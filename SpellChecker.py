# -*- coding: utf-8 -*-
"""Untitled15.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10ZvZ7TJ28H01prLhwwe_2jUI71Nasdhh
"""

# Import necessary libraries
import tensorflow as tf
from tensorflow.keras.layers import Input, LSTM, Embedding, Dense
from tensorflow.keras.models import Model
import numpy as np
from google.colab import files

# Upload the Sinhala dictionary file
uploaded = files.upload()

# Load dictionary words
with open(list(uploaded.keys())[0], 'r', encoding='utf-8') as file:
    sinhala_words = file.read().splitlines()

# Example sentences (add more pairs for better training)
data = [
    ("අද කාලෙදි අධ්‍යාපනෙත් වැරදී ඇත", "අද කාලේදි අධ්‍යාපනයත් වැරදී ඇත"),
    ("අලුත්ම මගුලක් සොයාගන්න අයුධ වගේම", "අලුත්ම මඟුලක් සොයාගන්න අයුතු වගේම"),
    ("සමහර අය විශාල අඩුපාඩුවක් අනුභව කරයි", "සමහර අය විශාල අඩුපාඩුවක් අනුභව කරයි"),
    ("අරගලය තුල ගොඩක් අය සාර්ථකත්වය ලබාගනී", "අරගලය තුළ ගොඩක් අය සාර්ථකත්වය ලබාගනී"),
    ("තොරතුරු තාක්ශනයෙහි වටිනාකම අගය නොකරයි", "තොරතුරු තාක්ෂණයේ වටිනාකම අගය නොකරයි")
]

# Separate inputs (with errors) and outputs (corrected)
input_texts = [pair[0] for pair in data]
target_texts = ["\t" + pair[1] + "\n" for pair in data]  # Add start ('\t') and end ('\n') tokens

# Create character sets
input_characters = set("".join(input_texts))
target_characters = set("".join(target_texts))

input_characters = sorted(list(input_characters))
target_characters = sorted(list(target_characters))

# Character-to-index and index-to-character mappings
input_token_index = {char: i for i, char in enumerate(input_characters)}
target_token_index = {char: i for i, char in enumerate(target_characters)}

# Reverse mappings
reverse_target_char_index = {i: char for char, i in target_token_index.items()}

# Define maximum sequence lengths
max_encoder_seq_length = max([len(text) for text in input_texts])
max_decoder_seq_length = max([len(text) for text in target_texts])

# Initialize empty arrays
encoder_input_data = np.zeros(
    (len(input_texts), max_encoder_seq_length, len(input_characters)), dtype="float32"
)
decoder_input_data = np.zeros(
    (len(target_texts), max_decoder_seq_length, len(target_characters)), dtype="float32"
)
decoder_target_data = np.zeros(
    (len(target_texts), max_decoder_seq_length, len(target_characters)), dtype="float32"
)

# Fill arrays
for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):
    for t, char in enumerate(input_text):
        encoder_input_data[i, t, input_token_index[char]] = 1.0
    for t, char in enumerate(target_text):
        decoder_input_data[i, t, target_token_index[char]] = 1.0
        if t > 0:
            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0

# Define the encoder
encoder_inputs = Input(shape=(None, len(input_characters)))
encoder = LSTM(256, return_state=True)
encoder_outputs, state_h, state_c = encoder(encoder_inputs)
encoder_states = [state_h, state_c]

# Define the decoder
decoder_inputs = Input(shape=(None, len(target_characters)))
decoder_lstm = LSTM(256, return_sequences=True, return_state=True)
decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)
decoder_dense = Dense(len(target_characters), activation="softmax")
decoder_outputs = decoder_dense(decoder_outputs)

# Combine encoder and decoder into a model
model = Model([encoder_inputs, decoder_inputs], decoder_outputs)

# Compile the model
model.compile(optimizer="rmsprop", loss="categorical_crossentropy")
model.summary()

# Train the model
model.fit(
    [encoder_input_data, decoder_input_data],
    decoder_target_data,
    batch_size=64,
    epochs=100,  # Increase for better accuracy
    validation_split=0.2,
)

# Save the trained model
model.save("sinhala_spelling_correction.h5")

# Load the saved model
model = tf.keras.models.load_model("sinhala_spelling_correction.h5")

# Encoder model for inference
encoder_model = Model(encoder_inputs, encoder_states)

# Decoder model for inference
decoder_state_input_h = Input(shape=(256,))
decoder_state_input_c = Input(shape=(256,))
decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]
decoder_outputs, state_h, state_c = decoder_lstm(
    decoder_inputs, initial_state=decoder_states_inputs
)
decoder_states = [state_h, state_c]
decoder_outputs = decoder_dense(decoder_outputs)
decoder_model = Model(
    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states
)

# Decode a sequence
def decode_sequence(input_seq):
    # Encode the input
    states_value = encoder_model.predict(input_seq)

    # Generate empty target sequence
    target_seq = np.zeros((1, 1, len(target_characters)))
    target_seq[0, 0, target_token_index["\t"]] = 1.0

    # Loop to generate the output sequence
    stop_condition = False
    decoded_sentence = ""
    while not stop_condition:
        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)

        # Get the most likely character
        sampled_token_index = np.argmax(output_tokens[0, -1, :])
        sampled_char = reverse_target_char_index[sampled_token_index]
        decoded_sentence += sampled_char

        # Exit condition
        if sampled_char == "\n" or len(decoded_sentence) > max_decoder_seq_length:
            stop_condition = True

        # Update target sequence
        target_seq = np.zeros((1, 1, len(target_characters)))
        target_seq[0, 0, sampled_token_index] = 1.0

        # Update states
        states_value = [h, c]

    return decoded_sentence

# Test a sample sentence
test_sentence = "තොරතුරු තාක්ශනයෙහි වටිනාකම අගය නොකරයි"
input_seq = np.zeros((1, max_encoder_seq_length, len(input_characters)))
for t, char in enumerate(test_sentence):
    input_seq[0, t, input_token_index[char]] = 1.0

corrected_sentence = decode_sequence(input_seq)
print(f"Original: {test_sentence}")
print(f"Corrected: {corrected_sentence}")